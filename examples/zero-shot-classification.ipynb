{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default Setting For PanDerm-Large\n",
      "This images is diagnosised as basal cell carcinoma.\n",
      "\n",
      "Label probs: \n",
      "nevus: 0.000\n",
      "basal cell carcinoma: 1.000\n",
      "actinic keratosis: 0.000\n",
      "seborrheic keratosis: 0.000\n",
      "squamous cell carcinoma: 0.000\n",
      "melanoma: 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "project_root = os.getcwd()\n",
    "src_path = os.path.join(project_root, '../src')\n",
    "sys.path.insert(0, project_root)\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "import open_clip\n",
    "\n",
    "# Call PanDerm2 with huggingface checkpoint\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('hf-hub:redlessone/PanDerm2')\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "# Similarly, we init the tokenizer with huggingface checkpoint\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:redlessone/PanDerm2')\n",
    "\n",
    "# Read example image\n",
    "image = preprocess(Image.open(\"PAT_8_15_820.png\")).unsqueeze(0)\n",
    "\n",
    "# Here we will use the disease label in PAD dataset to build text prompts\n",
    "PAD_CLASSNAMES= [\"nevus\",  \"basal cell carcinoma\",\"actinic keratosis\", \"seborrheic keratosis\",\"squamous cell carcinoma\",\"melanoma\"]\n",
    "template = lambda c: f'This is a skin image of {c}'\n",
    "\n",
    "text = tokenizer([template(c) for c in PAD_CLASSNAMES])\n",
    "\n",
    "with torch.no_grad(), torch.autocast(\"cpu\"):\n",
    "    image_features = model.encode_image(image) # Encode image to visual feature\n",
    "    text_features = model.encode_text(text) # Encode text to text feature\n",
    "    \n",
    "    # Normalize\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute similarity\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "final_prediction = PAD_CLASSNAMES[torch.argmax(text_probs[0])]\n",
    "\n",
    "print(f'This images is diagnosised as {final_prediction}.')\n",
    "\n",
    "print(\"\\nLabel probs: \")\n",
    "for idx, label in enumerate(PAD_CLASSNAMES):\n",
    "    print(f\"{PAD_CLASSNAMES[idx]}: {text_probs[:, idx].item():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.19 ('PanDerm-v2-SAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e49bbb112f699f6056299a0e687617de3ddd5b071f1dd053f5b9b40ffc44df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
